{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11a72ed5",
   "metadata": {},
   "source": [
    "## WEM project: JVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9e20e3",
   "metadata": {},
   "source": [
    "#### Project's members:  Campos Carvalho Cédric, Feuillade Florian, Ramosaj Nicolas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9a894b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicolas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from vaderSentiment_fr.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "from textblob_fr import PatternTagger, PatternAnalyzer\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098fff57",
   "metadata": {},
   "source": [
    "#### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3143722b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>date</th>\n",
       "      <th>grade</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Torzeka</td>\n",
       "      <td>2022-02-28 20:54:00</td>\n",
       "      <td>20</td>\n",
       "      <td>Fan inconditionnel de FS, j’attendais ER comme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ranni_la_Witch</td>\n",
       "      <td>2022-03-24 01:02:00</td>\n",
       "      <td>20</td>\n",
       "      <td>Tout d'abord précision importante: le jeu a ét...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sworm_cod</td>\n",
       "      <td>2022-03-20 16:40:00</td>\n",
       "      <td>11</td>\n",
       "      <td>franchement, un jeu ou si tu ne parles pas a t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vergilesco</td>\n",
       "      <td>2022-02-25 11:03:00</td>\n",
       "      <td>9</td>\n",
       "      <td>Portage honteux sur PC, du stuttering sur une ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           player                date  grade  \\\n",
       "0         Torzeka 2022-02-28 20:54:00     20   \n",
       "1  Ranni_la_Witch 2022-03-24 01:02:00     20   \n",
       "2       Sworm_cod 2022-03-20 16:40:00     11   \n",
       "3      Vergilesco 2022-02-25 11:03:00      9   \n",
       "\n",
       "                                             comment  \n",
       "0  Fan inconditionnel de FS, j’attendais ER comme...  \n",
       "1  Tout d'abord précision importante: le jeu a ét...  \n",
       "2  franchement, un jeu ou si tu ne parles pas a t...  \n",
       "3  Portage honteux sur PC, du stuttering sur une ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_json(r'data/comments_elden.json')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae09a57e",
   "metadata": {},
   "source": [
    "#### Function to convert range[-1, 1] to [0, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b3fdf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToGrade(percentage):\n",
    "    if percentage < 0:\n",
    "        grade = np.ceil(12 * percentage + 12)\n",
    "    else:\n",
    "        grade = np.ceil(8 * percentage + 12)\n",
    "    return grade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136fd12d",
   "metadata": {},
   "source": [
    "#### Sentiment analysis with BlobText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba3f5b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment from Torzeka is 14.0\n",
      "comment from Ranni_la_Witch is 14.0\n",
      "comment from Sworm_cod is 12.0\n",
      "comment from Vergilesco is 11.0\n",
      "comment from Torzeka is 0.4046739130434782\n",
      "comment from Ranni_la_Witch is 0.5296884128529699\n",
      "comment from Sworm_cod is 0.35833333333333334\n",
      "comment from Vergilesco is 0.4708333333333334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentiment analysis using TextBlob range is [-1, 1]\n",
    "# Dedicated for French: https://github.com/sloria/textblob-fr\n",
    "y_pred_textblob = [TextBlob(sent, pos_tagger=PatternTagger(), analyzer=PatternAnalyzer()).sentiment for sent in dataset['comment']]\n",
    "[print('comment from', dataset['player'][i], 'is', convertToGrade(y_pred[0])) for i, y_pred in enumerate(y_pred_textblob)]\n",
    "[print('comment from', dataset['player'][i], 'is', y_pred[1]) for i, y_pred in enumerate(y_pred_textblob)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a387f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment from Torzeka is 12.0\n",
      "comment from Ranni_la_Witch is 15.0\n",
      "comment from Sworm_cod is 13.0\n",
      "comment from Vergilesco is 0.0\n",
      "comment from Torzeka is 0.6799999999999999\n",
      "comment from Ranni_la_Witch is 0.7520833333333332\n",
      "comment from Sworm_cod is 0.7857142857142857\n",
      "comment from Vergilesco is 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://textblob.readthedocs.io/en/dev/\n",
    "# Based on English version\n",
    "y_pred_textblob = [TextBlob(sent).sentiment for sent in dataset['comment']]\n",
    "[print('comment from', dataset['player'][i], 'is', convertToGrade(y_pred.polarity)) for i, y_pred in enumerate(y_pred_textblob)]\n",
    "[print('comment from', dataset['player'][i], 'is', y_pred.subjectivity) for i, y_pred in enumerate(y_pred_textblob)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d36024",
   "metadata": {},
   "source": [
    "#### Sentiment analysis with Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a634854f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment from Torzeka is 20.0\n",
      "comment from Ranni_la_Witch is 20.0\n",
      "comment from Sworm_cod is 19.0\n",
      "comment from Vergilesco is 3.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentiment analysis using Vader range is [-1, 1]\n",
    "# https://github.com/cjhutto/vaderSentiment\n",
    "vader_analyser = SentimentIntensityAnalyzer()\n",
    "y_pred_vader = [vader_analyser.polarity_scores(sent) for sent in dataset['comment']]\n",
    "\n",
    "[print('comment from', dataset['player'][i], 'is', convertToGrade(y_pred['compound'])) for i, y_pred in enumerate(y_pred_vader)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299ce955",
   "metadata": {},
   "source": [
    "#### Sentiment analysis with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e90cfa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma_newtag(taggedterm):\n",
    "    \"\"\" we need to convert the output of the POS tagger in terms of tag names to correspond to the input of sentiwordnet\n",
    "        Arguments:\n",
    "        term            - input tuple of token and NLTK POS \n",
    "  \n",
    "        \n",
    "        Returns:\n",
    "        lemma           - the lemma of the token\n",
    "        newtag          - the pos tag of the token in the sentiwordnet form\n",
    "        \"\"\" \n",
    "    wnl = nltk.WordNetLemmatizer()\n",
    "    lemma=wnl.lemmatize(taggedterm[0])\n",
    "    if taggedterm[1].startswith('NN'):\n",
    "            newtag='n'\n",
    "    elif taggedterm[1].startswith('JJ'):\n",
    "            newtag='a'\n",
    "    elif taggedterm[1].startswith('V'):\n",
    "            newtag='v'\n",
    "    elif taggedterm[1].startswith('R'):\n",
    "            newtag='r'\n",
    "    else:\n",
    "            newtag=''\n",
    "    return lemma,newtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84e8827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swn_score(taggedsent):\n",
    "    score_list={}\n",
    "    for term in taggedsent:\n",
    "        lemma,newtag=lemma_newtag(term) \n",
    "        if(newtag!=''): \n",
    "            #BEGIN REMOVE   \n",
    "            synsets = list(swn.senti_synsets(lemma, newtag))\n",
    "            #Getting average of all possible sentiments, as you requested \n",
    "            if(len(synsets)>0):\n",
    "                score=0\n",
    "                for syn in synsets:\n",
    "                    score+=syn.pos_score()-syn.neg_score()\n",
    "                score_list[lemma]=score/len(synsets)\n",
    "            #END REMOVE\n",
    "    return score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "870905d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg', 'neg', 'neg', 'neg']\n"
     ]
    }
   ],
   "source": [
    "def sentiwordnet_sentiment_analysis(corpus, use_synsets_mean=True):\n",
    "    \n",
    "    labels=[]\n",
    "    scores=[]\n",
    "    \n",
    "    for document in corpus:\n",
    "        assert(1==1)\n",
    "        sentences = nltk.sent_tokenize(document)\n",
    "\n",
    "        alltokens = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "        taggedlist=[nltk.pos_tag(stoken) for stoken in alltokens]       \n",
    "\n",
    "        score = {}\n",
    "        for sent in taggedlist:\n",
    "            score.update(swn_score(sent))\n",
    "            \n",
    "        if sum(score.values())>0:\n",
    "            labels.append('pos')\n",
    "        else:\n",
    "            labels.append('neg')\n",
    "        scores.append(score)            \n",
    "    return labels, scores\n",
    "\n",
    "predicted_labels, scores = sentiwordnet_sentiment_analysis(dataset['comment'])\n",
    "\n",
    "try:\n",
    "    print(predicted_labels)\n",
    "except:\n",
    "    print ('The function sentiwordnet_sentiment_analysis needs your attention.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dd3c1c",
   "metadata": {},
   "source": [
    "#### Naive approach extract words and do a mean on the positive or negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72e65835",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Words/positive-words.txt', errors='ignore') as opened:\n",
    "    contents=opened.read()\n",
    "contents_lines=['a+'] + contents.split('a+')[1].split('\\n')\n",
    "\n",
    "positive_words = [x for x in contents_lines if len(x)>0]\n",
    "\n",
    "\n",
    "with open('Words/negative-words.txt', errors='ignore') as opened:\n",
    "    contents=opened.read()\n",
    "contents_lines=['2-faced'] + contents.split('2-faced')[1].split('\\n')\n",
    "\n",
    "negative_words = [x for x in contents_lines if len(x)>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7430590f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment from Torzeka is 8.0\n",
      "comment from Ranni_la_Witch is 12.0\n",
      "comment from Sworm_cod is 12.0\n",
      "comment from Vergilesco is 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def naiveScore(corpus):\n",
    "    scores=[]\n",
    "    for document in corpus:\n",
    "\n",
    "        document_words = set(word for word in word_tokenize(document))\n",
    "        positive = list(document_words.intersection(positive_words))\n",
    "        negative = list(document_words.intersection(negative_words))\n",
    "        score = (len(positive) - len(negative))/(len(positive) + len(negative)) if (len(positive) + len(negative)) != 0 else 0\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "    \n",
    "y_pred_naive = naiveScore(dataset['comment'])\n",
    "[print('comment from', dataset['player'][i], 'is', convertToGrade(y_pred)) for i, y_pred in enumerate(y_pred_naive)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e01bd27",
   "metadata": {},
   "source": [
    "#### Sentiment analysis with transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f9e3964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFCamembertForSequenceClassification.\n",
      "\n",
      "All the layers of TFCamembertForSequenceClassification were initialized from the model checkpoint at tblard/tf-allocine.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFCamembertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/tblard/tf-allocine and https://github.com/TheophileBlard/french-sentiment-analysis-with-bert\n",
    "# Limited to 512 tokens\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tblard/tf-allocine\")\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"tblard/tf-allocine\")\n",
    "\n",
    "nlp = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62c21a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment from Vergilesco is NEGATIVE\n",
      "[{'label': 'POSITIVE', 'score': 0.9862489104270935}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9974060654640198}]\n"
     ]
    }
   ],
   "source": [
    "#[print('comment from', dataset['player'][i], 'is', nlp(comment)) for i, comment in enumerate(dataset['comment'])]\n",
    "print('comment from', dataset['player'][3], 'is', nlp(dataset['comment'][3])[0]['label'])\n",
    "\n",
    "print(nlp(\"Juste whoaaahouuu !\")) # POSITIVE\n",
    "print(nlp(\"NUL...A...CHIER ! FIN DE TRANSMISSION.\")) # NEGATIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4d4fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
